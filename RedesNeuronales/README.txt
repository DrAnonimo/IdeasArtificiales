# ClasificaciÃ³n de DÃ­gitos MNIST con Redes Neuronales

Este repositorio contiene una implementaciÃ³n de una red neuronal para clasificar dÃ­gitos escritos a mano del dataset MNIST, usando TensorFlow/Keras.

## ğŸ“‹ Contenido del Repositorio
- `mnist_neural_network.py`: Script principal con la implementaciÃ³n completa
- `README.md`: Este archivo con la documentaciÃ³n

## ğŸ§  DescripciÃ³n del Modelo
ImplementaciÃ³n de una red neuronal fully-connected (Dense) con:
- **2 capas ocultas** (128 y 64 neuronas, activaciÃ³n ReLU)
- **Capa de salida** (10 neuronas, activaciÃ³n softmax)
- Optimizador: Adam
- FunciÃ³n de pÃ©rdida: Categorical Crossentropy

## ğŸ› ï¸ Estructura del CÃ³digo

### 1. Carga y Preprocesamiento de Datos
```python
# Cargar dataset MNIST
(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()

# NormalizaciÃ³n y reshape
X_train = X_train.astype("float32") / 255
X_train = X_train.reshape((60000, 28 * 28))

### 2. ConstrucciÃ³n del modelo
```python
model = keras.Sequential([
    layers.Dense(128, activation='relu', input_shape=(28 * 28,)),
    layers.Dense(64, activation='relu'),
    layers.Dense(10, activation='softmax')
])

### 3. Ajuste de parÃ¡metros
```python
history = model.fit(X_train, y_train,
                    epochs=10,
                    batch_size=64,
                    validation_split=0.2)

### 4. EvaluaciÃ³n
- GrÃ¡ficos de precisiÃ³n y pÃ©rdida durante el entrenamiento
- EvaluaciÃ³n en el conjunto de test
- FunciÃ³n para probar predicciones individuales

ğŸ“Š Resultados Esperados
- PrecisiÃ³n en entrenamiento: ~98%
- PrecisiÃ³n en validaciÃ³n: ~97%
- PrecisiÃ³n en test: ~96-97%

ğŸš€ CÃ³mo Ejecutar
Instalar dependencias:
```python
pip install numpy matplotlib tensorflow
Ejecutar el script:
```python
python mnist_neural_network.py

ğŸ“Œ Visualizaciones Incluidas
- Muestra de 10 dÃ­gitos del dataset
- GrÃ¡ficos de evoluciÃ³n de precisiÃ³n y pÃ©rdida
- PredicciÃ³n en una imagen aleatoria de test
