# API Call Analysis & Optimization

## üö® Current API Call Volume

### Historical Data Collection (30 days)
```
Per Day:
- 10 search queries √ó 1 Tavily API call = 10 calls
- 1 second delay between queries = 10 seconds
- 2 second delay between days = 2 seconds

Total for 30 days:
- 30 days √ó 10 calls = 300 Tavily API calls
- 30 days √ó 5 articles √ó 1 OpenAI call = 150 OpenAI calls
- Total: 450 API calls
- Time: ~6-8 minutes
```

### Daily Collection (Current System)
```
Per Day:
- 9 search queries √ó 1 Tavily API call = 9 calls
- 10 articles √ó 1 OpenAI call = 10 calls
- Total: 19 API calls per day
```

## üîç Why So Many API Calls?

### 1. **Multiple Search Queries Per Day**
```python
# Current implementation uses 10 queries per day:
base_queries = [
    f"AI news {date_str}",
    f"artificial intelligence {date_str}",
    f"AI startup funding {date_str}",
    f"AI market {date_str}",
    f"AI technology {date_str}",
    f"AI investment {date_str}",
    f"AI bubble {date_str}",
    f"AI regulation {date_str}",
    f"AI jobs {date_str}",
    f"AI research {date_str}"
]
```

### 2. **Redundant Searches**
- Each query searches for the same day
- Many queries return similar articles
- No deduplication across queries

### 3. **Individual Article Analysis**
- Each article analyzed separately with OpenAI
- No batch processing
- No caching of similar content

## üöÄ Optimization Solutions

### Option 1: **Reduce Search Queries** (Immediate)
```python
# Reduce from 10 to 3-4 queries per day
optimized_queries = [
    f"AI news {date_str}",
    f"AI startup funding {date_str}",
    f"AI market bubble {date_str}",
    f"AI regulation {date_str}"
]

# API calls reduced from 300 to 120 (60% reduction)
```

### Option 2: **Smart Query Selection** (Better)
```python
# Use different queries based on day of week
def get_optimized_queries(target_date):
    if target_date.weekday() == 0:  # Monday
        return [f"AI weekend news {date_str}", f"AI market {date_str}"]
    elif target_date.weekday() < 5:  # Weekday
        return [f"AI news {date_str}", f"AI funding {date_str}"]
    else:  # Weekend
        return [f"AI research {date_str}", f"AI technology {date_str}"]
```

### Option 3: **Batch Processing** (Best)
```python
# Process multiple articles in one OpenAI call
def analyze_articles_batch(articles):
    # Combine articles into single prompt
    combined_content = "\n\n".join([f"Title: {a['title']}\nContent: {a['content']}" for a in articles])
    
    # Single API call for all articles
    analysis = llm.analyze(combined_content)
    
    # Split results back to individual articles
    return split_analysis(analysis)
```

### Option 4: **Caching & Deduplication** (Advanced)
```python
# Cache similar articles
def get_cached_analysis(article_content):
    content_hash = hashlib.md5(article_content.encode()).hexdigest()
    if content_hash in analysis_cache:
        return analysis_cache[content_hash]
    
    # Only analyze if not cached
    analysis = analyze_article(article_content)
    analysis_cache[content_hash] = analysis
    return analysis
```

## üìä Optimized Implementation

### Immediate Fix (60% reduction)
```python
def _get_optimized_queries(self, target_date: datetime.date) -> List[str]:
    """Optimized queries - reduced from 10 to 4"""
    date_str = target_date.strftime("%Y-%m-%d")
    
    # Core queries only
    return [
        f"AI news {date_str}",
        f"AI startup funding {date_str}",
        f"AI market bubble {date_str}",
        f"AI regulation {date_str}"
    ]
```

### Smart Query Selection
```python
def _get_smart_queries(self, target_date: datetime.date) -> List[str]:
    """Smart query selection based on day of week"""
    date_str = target_date.strftime("%Y-%m-%d")
    weekday = target_date.weekday()
    
    if weekday == 0:  # Monday - weekend coverage
        return [
            f"AI weekend news {date_str}",
            f"AI market {date_str}",
            f"AI funding {date_str}"
        ]
    elif weekday < 5:  # Weekday - business focus
        return [
            f"AI news {date_str}",
            f"AI startup funding {date_str}",
            f"AI market bubble {date_str}"
        ]
    else:  # Weekend - research focus
        return [
            f"AI research {date_str}",
            f"AI technology {date_str}",
            f"AI innovation {date_str}"
        ]
```

### Batch Analysis
```python
def _analyze_articles_batch(self, articles: List[Dict[str, Any]]) -> List[NewsAnalysis]:
    """Analyze multiple articles in one API call"""
    if not articles:
        return []
    
    # Combine articles for batch processing
    combined_prompt = self._create_batch_prompt(articles)
    
    # Single API call
    batch_response = self.llm.invoke(combined_prompt)
    
    # Parse and split results
    return self._parse_batch_response(batch_response, articles)
```

## üéØ Recommended Implementation

### Phase 1: Quick Fix (Immediate)
1. **Reduce queries from 10 to 4** per day
2. **Add better deduplication** across queries
3. **Implement smart query selection** based on day of week

### Phase 2: Optimization (Next)
1. **Batch article analysis** (5 articles per API call)
2. **Implement caching** for similar content
3. **Add query result deduplication**

### Phase 3: Advanced (Future)
1. **Machine learning** for query optimization
2. **Predictive caching** based on patterns
3. **Dynamic query selection** based on results

## üìà Expected Improvements

| Optimization | API Calls (30 days) | Time | Accuracy |
|-------------|-------------------|------|----------|
| **Current** | 450 calls | 6-8 min | 85% |
| **Phase 1** | 180 calls | 3-4 min | 80% |
| **Phase 2** | 90 calls | 2-3 min | 85% |
| **Phase 3** | 60 calls | 1-2 min | 90% |

## üîß Implementation Code

### Quick Fix Implementation
```python
def _get_optimized_queries(self, target_date: datetime.date) -> List[str]:
    """Optimized queries - 60% reduction in API calls"""
    date_str = target_date.strftime("%Y-%m-%d")
    
    # Smart query selection based on day of week
    weekday = target_date.weekday()
    
    if weekday == 0:  # Monday - weekend coverage
        return [
            f"AI weekend news {date_str}",
            f"AI market {date_str}",
            f"AI funding {date_str}"
        ]
    elif weekday < 5:  # Weekday - business focus
        return [
            f"AI news {date_str}",
            f"AI startup funding {date_str}",
            f"AI market bubble {date_str}",
            f"AI regulation {date_str}"
        ]
    else:  # Weekend - research focus
        return [
            f"AI research {date_str}",
            f"AI technology {date_str}",
            f"AI innovation {date_str}"
        ]
```

### Batch Analysis Implementation
```python
def _analyze_articles_batch(self, articles: List[Dict[str, Any]]) -> List[NewsAnalysis]:
    """Analyze multiple articles in one API call"""
    if not articles:
        return []
    
    # Process in batches of 5
    batch_size = 5
    results = []
    
    for i in range(0, len(articles), batch_size):
        batch = articles[i:i + batch_size]
        batch_analysis = self._process_batch(batch)
        results.extend(batch_analysis)
    
    return results

def _process_batch(self, articles: List[Dict[str, Any]]) -> List[NewsAnalysis]:
    """Process a batch of articles"""
    # Create combined prompt
    combined_content = "\n\n---ARTICLE---\n".join([
        f"Title: {a['title']}\nContent: {a['content'][:1000]}"
        for a in articles
    ])
    
    # Single API call for batch
    prompt = f"Analyze these articles for bubble indicators:\n\n{combined_content}"
    response = self.llm.invoke(prompt)
    
    # Parse and return individual analyses
    return self._parse_batch_response(response, articles)
```

## üöÄ Quick Start Optimization

Would you like me to implement the **Phase 1 optimization** right now? This would:

1. **Reduce API calls by 60%** (from 450 to 180 for 30 days)
2. **Cut collection time in half** (from 6-8 minutes to 3-4 minutes)
3. **Maintain 80%+ accuracy** with smart query selection
4. **Add better deduplication** to avoid redundant articles

This is a simple change that will immediately solve your API call volume issue!
